07/21/2024 07:24:34 - INFO - __main__ - cleaning process started...
07/21/2024 07:24:35 - INFO - serving.ddp_worker - DDP: python loop: data_id=0/1 thread started.
INFO:     Started server process [2433]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8081 (Press CTRL+C to quit)
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
initializing with layer-device setup: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
device -1 loading file pytorch_model-00001-of-00003.bin:   0%|          | 0/539 [00:00<?, ?it/s]device -1 loading file pytorch_model-00001-of-00003.bin:   0%|          | 1/539 [00:00<06:15,  1.43it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  16%|█▌        | 86/539 [00:00<00:03, 144.94it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  35%|███▍      | 186/539 [00:00<00:01, 310.50it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  52%|█████▏    | 280/539 [00:01<00:00, 446.22it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  68%|██████▊   | 365/539 [00:01<00:00, 539.88it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  83%|████████▎ | 447/539 [00:01<00:00, 562.97it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  97%|█████████▋| 522/539 [00:01<00:00, 575.23it/s]device -1 loading file pytorch_model-00001-of-00003.bin: 100%|██████████| 539/539 [00:01<00:00, 391.74it/s]
device -1 loading file pytorch_model-00002-of-00003.bin:   0%|          | 0/861 [00:00<?, ?it/s]device -1 loading file pytorch_model-00002-of-00003.bin:   8%|▊         | 70/861 [00:00<00:01, 692.93it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  20%|██        | 176/861 [00:00<00:00, 874.30it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  33%|███▎      | 282/861 [00:00<00:00, 923.39it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  44%|████▎     | 375/861 [00:00<00:00, 754.10it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  53%|█████▎    | 454/861 [00:00<00:00, 642.92it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  61%|██████    | 522/861 [00:00<00:00, 592.82it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  68%|██████▊   | 584/861 [00:00<00:00, 561.01it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  75%|███████▌  | 646/861 [00:01<00:00, 570.01it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  82%|████████▏ | 705/861 [00:01<00:00, 529.23it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  89%|████████▊ | 763/861 [00:01<00:00, 531.07it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  95%|█████████▍| 817/861 [00:01<00:00, 510.40it/s]device -1 loading file pytorch_model-00002-of-00003.bin: 100%|██████████| 861/861 [00:01<00:00, 601.35it/s]
device -1 loading file pytorch_model-00003-of-00003.bin:   0%|          | 0/83 [00:00<?, ?it/s]device -1 loading file pytorch_model-00003-of-00003.bin:   1%|          | 1/83 [00:00<01:11,  1.15it/s]device -1 loading file pytorch_model-00003-of-00003.bin: 100%|██████████| 83/83 [00:00<00:00, 85.41it/s]
device -1 loading lora default:   0%|          | 0/560 [00:00<?, ?it/s]device -1 loading lora default:   3%|▎         | 16/560 [00:00<00:03, 154.73it/s]device -1 loading lora default:   6%|▌         | 32/560 [00:00<00:03, 157.63it/s]device -1 loading lora default:   9%|▊         | 48/560 [00:00<00:03, 155.68it/s]device -1 loading lora default:  13%|█▎        | 71/560 [00:00<00:02, 175.46it/s]device -1 loading lora default:  16%|█▌        | 89/560 [00:00<00:02, 168.84it/s]device -1 loading lora default:  19%|█▉        | 106/560 [00:00<00:02, 166.47it/s]device -1 loading lora default:  23%|██▎       | 127/560 [00:00<00:02, 172.81it/s]device -1 loading lora default:  26%|██▌       | 145/560 [00:00<00:02, 164.21it/s]device -1 loading lora default:  29%|██▉       | 162/560 [00:00<00:02, 163.68it/s]device -1 loading lora default:  33%|███▎      | 183/560 [00:01<00:02, 169.63it/s]device -1 loading lora default:  36%|███▌      | 200/560 [00:01<00:02, 165.33it/s]device -1 loading lora default:  39%|███▉      | 217/560 [00:01<00:02, 162.75it/s]device -1 loading lora default:  43%|████▎     | 239/560 [00:01<00:01, 172.19it/s]device -1 loading lora default:  46%|████▌     | 257/560 [00:01<00:01, 168.25it/s]device -1 loading lora default:  49%|████▉     | 274/560 [00:01<00:01, 167.67it/s]device -1 loading lora default:  53%|█████▎    | 295/560 [00:01<00:01, 173.80it/s]device -1 loading lora default:  56%|█████▌    | 313/560 [00:01<00:01, 168.72it/s]device -1 loading lora default:  59%|█████▉    | 330/560 [00:01<00:01, 167.19it/s]device -1 loading lora default:  63%|██████▎   | 351/560 [00:02<00:01, 172.88it/s]device -1 loading lora default:  66%|██████▌   | 369/560 [00:02<00:01, 168.90it/s]device -1 loading lora default:  69%|██████▉   | 386/560 [00:02<00:01, 168.03it/s]device -1 loading lora default:  73%|███████▎  | 407/560 [00:02<00:00, 174.23it/s]device -1 loading lora default:  76%|███████▌  | 425/560 [00:02<00:00, 169.90it/s]device -1 loading lora default:  79%|███████▉  | 442/560 [00:02<00:00, 168.83it/s]device -1 loading lora default:  83%|████████▎ | 463/560 [00:02<00:00, 174.60it/s]device -1 loading lora default:  86%|████████▌ | 481/560 [00:02<00:00, 168.27it/s]device -1 loading lora default:  89%|████████▉ | 498/560 [00:02<00:00, 166.52it/s]device -1 loading lora default:  93%|█████████▎| 519/560 [00:03<00:00, 173.16it/s]device -1 loading lora default:  96%|█████████▌| 537/560 [00:03<00:00, 167.97it/s]device -1 loading lora default:  99%|█████████▉| 554/560 [00:03<00:00, 167.48it/s]device -1 loading lora default: 100%|██████████| 560/560 [00:03<00:00, 169.19it/s]
initializing cpp Qwen1.5 model, with num_layers=40, max_dynamic_bsz=16
Data parallel worker data_id=0 has layers on devices [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
python smem psm_61966e93 binded with size=2637824..
lora configs loaded:
default: r=8, modules=[k_proj,gate_proj,o_proj,v_proj,down_proj,q_proj,up_proj]
data_id 0 is using devices[0, 1)
setting up inference on data_id=0, using devices=[0, 1), num_layers=40, max_dynamic_bsz=16, max_BL=5120
device 0 initialized cublas handler
allocating kv-cache pools for data_id=0, size=[BL(5120), Hkv(40)*D(128)] * layer_num(40 in 1 stages) * 2(KV)
kv cache layer ptr: key&value separation=1048576000, layer_stride=26214400
stage with layers[0, 40) initialized the starting pointers for each layer.
initializing BatchInputPreparer, max_B=16, max_BL=5120
input preparer initialized...allocating cos & sin, max_len=5120, kv_channels=128, gpu_id=0
preparing gpu rotary cos and sin with [seq_length, channel]=[5120, 128] on device 0
data_id=0 loading all cpu weights to gpus according to device map.
offloaded param model.embed_tokens.weight to cpu
before buffer preparing
allocated gptq buffers on device 0: state[5120, 1], dq=[1, 73400320]. starting make_q4
quant weights prepared for data_id=0
new curand initializing with key=0, curandSize=256x48
### device (0): mem_free=10351MB, mem_total=24575MB
warmup prefilling...
warming up for data_id=0, lora detected=default, prefill_len=1876 ...
KV_CACHING[gpu0]: successful allocate maxlen=1896, req_id=warmup0001. Empty memory, numel=<<+9707520>>
KV_CACHING[gpu0]: successful allocate maxlen=44, req_id=warmup0002. MemoryInfo=[0,0]_[0,9707520]_<<+225280>>_[26214400]
warmup decoding...
KV_CACHING[gpu0]: free cache block=warmup0001, remaining block_ct=1
KV_CACHING[gpu0]: free cache block=warmup0002, remaining block_ct=0
07/21/2024 07:26:14 - INFO - serving.ddp_worker - DDP: data_id=0 model loaded...
warmup finished for data_id=0
loading_ct=1
<=============data parallel id 0 ready for inference.===========
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ1', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51852 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ1, queue=1, dict=1
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ0', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51862 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ0, queue=2, dict=2
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ3', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ2', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ4', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ5', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ6', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51868 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ3, queue=3, dict=3
INFO:     127.0.0.1:51880 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ2, queue=4, dict=4
INFO:     127.0.0.1:51884 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ4, queue=5, dict=5
INFO:     127.0.0.1:51892 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ5, queue=6, dict=6
INFO:     127.0.0.1:51906 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ6, queue=7, dict=7
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ7', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ9', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ8', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ10', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ11', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ12', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ13', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ14', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:27:38 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ15', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51912 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ7, queue=8, dict=8
INFO:     127.0.0.1:51920 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ9, queue=9, dict=9
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ1
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=1, req_id=REQ1, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ0
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=2, req_id=REQ0, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ3
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=3, req_id=REQ3, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ2
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=4, req_id=REQ2, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ4
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=5, req_id=REQ4, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ5
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=6, req_id=REQ5, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ6
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=7, req_id=REQ6, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ7
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=8, req_id=REQ7, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ9
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=9, req_id=REQ9, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
INFO:     127.0.0.1:51934 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ8, queue=1, dict=10
INFO:     127.0.0.1:51948 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ10, queue=2, dict=11
INFO:     127.0.0.1:51952 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ11, queue=3, dict=12
INFO:     127.0.0.1:51956 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ12, queue=4, dict=13
INFO:     127.0.0.1:51972 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ13, queue=5, dict=14
INFO:     127.0.0.1:51976 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ14, queue=6, dict=15
INFO:     127.0.0.1:51992 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:27:38 - INFO - serving.pool_client - CLIENT: added request REQ15, queue=7, dict=16
POOL: Added to queue: request_id=REQ1, queue_size=1
POOL: Added to queue: request_id=REQ0, queue_size=2
POOL: Added to queue: request_id=REQ3, queue_size=3
POOL: Added to queue: request_id=REQ2, queue_size=4
POOL: Added to queue: request_id=REQ4, queue_size=5
POOL: Added to queue: request_id=REQ5, queue_size=6
POOL: Added to queue: request_id=REQ6, queue_size=7
POOL: Added to queue: request_id=REQ7, queue_size=8
POOL: Added to queue: request_id=REQ9, queue_size=9
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ1. Empty memory, numel=<<+1310720>>
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ3. MemoryInfo=[0,0]_[0,1310720]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ4. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ6. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ9. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ0. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ5. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_<<+1310720>>_[26214400]
BATCHING: 7 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ1) (256,REQ3) (256,REQ4) (256,REQ6) (256,REQ9) (256,REQ0) (256,REQ5) 
GENERATION RELOADED: unfinished_decode_ct=0, new_prefill=[(0|44|default|-50),(1|88|default|-47),(2|132|default|-44),(3|176|default|-42),(4|220|default|-39),(5|264|default|-49),(6|308|default|-43),], req_ids=[REQ1,REQ3,REQ4,REQ6,REQ9,REQ0,REQ5,]
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ8
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=10, req_id=REQ8, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ10
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=11, req_id=REQ10, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ11
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=12, req_id=REQ11, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ12
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=13, req_id=REQ12, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ13
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=14, req_id=REQ13, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ14
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=15, req_id=REQ14, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ15
07/21/2024 07:27:38 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=16, req_id=REQ15, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ8, queue_size=3
POOL: Added to queue: request_id=REQ10, queue_size=4
POOL: Added to queue: request_id=REQ11, queue_size=5
POOL: Added to queue: request_id=REQ12, queue_size=6
POOL: Added to queue: request_id=REQ13, queue_size=7
POOL: Added to queue: request_id=REQ14, queue_size=8
POOL: Added to queue: request_id=REQ15, queue_size=9
TOKEN_UPDATE: first frame token generated for req=REQ1, new_pos=0, new_len=45, token=109944, bid=0, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ3, new_pos=45, new_len=45, token=109944, bid=1, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ4, new_pos=90, new_len=45, token=109944, bid=2, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ6, new_pos=135, new_len=45, token=109944, bid=3, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ9, new_pos=180, new_len=45, token=109944, bid=4, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ0, new_pos=225, new_len=45, token=109944, bid=5, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ5, new_pos=270, new_len=45, token=109944, bid=6, appending to context
GENERATION DECODING: len=7, examples=[(0|45),(1|90),(2|135),(3|180),(4|225),(5|270),(6|315),], req_ids=[REQ1,REQ3,REQ4,REQ6,REQ9,REQ0,REQ5,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ2. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ8. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ11. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ13. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ15. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ7. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ12. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_<<+1310720>>_[26214400]
BATCHING: 7 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ2) (256,REQ8) (256,REQ11) (256,REQ13) (256,REQ15) (256,REQ7) (256,REQ12) 
GENERATION RELOADED: unfinished_decode_ct=7, new_prefill=[(0|44|default|-45),(1|88|default|-936),(2|132|default|-933),(3|176|default|-930),(4|220|default|-928),(5|264|default|-40),(6|308|default|-932),], req_ids=[REQ2,REQ8,REQ11,REQ13,REQ15,REQ7,REQ12,]
TOKEN_UPDATE: first frame token generated for req=REQ2, new_pos=329, new_len=45, token=109944, bid=7, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ8, new_pos=374, new_len=45, token=109944, bid=8, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ11, new_pos=419, new_len=45, token=109944, bid=9, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ13, new_pos=464, new_len=45, token=109944, bid=10, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ15, new_pos=509, new_len=45, token=109944, bid=11, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ7, new_pos=554, new_len=45, token=109944, bid=12, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ12, new_pos=599, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|47),(1|94),(2|141),(3|188),(4|235),(5|282),(6|329),(7|374),(8|419),(9|464),(10|509),(11|554),(12|599),(13|644),], req_ids=[REQ1,REQ3,REQ4,REQ6,REQ9,REQ0,REQ5,REQ2,REQ8,REQ11,REQ13,REQ15,REQ7,REQ12,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ10. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ10) 
GENERATION RELOADED: unfinished_decode_ct=14, new_prefill=[(0|44|default|-935),], req_ids=[REQ10,]
TOKEN_UPDATE: first frame token generated for req=REQ10, new_pos=672, new_len=45, token=109944, bid=14, appending to context
GENERATION DECODING: len=15, examples=[(0|49),(1|98),(2|147),(3|196),(4|245),(5|294),(6|343),(7|390),(8|437),(9|484),(10|531),(11|578),(12|625),(13|672),(14|717),], req_ids=[REQ1,REQ3,REQ4,REQ6,REQ9,REQ0,REQ5,REQ2,REQ8,REQ11,REQ13,REQ15,REQ7,REQ12,REQ10,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ14. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_[18350080,19660800]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ14) 
GENERATION RELOADED: unfinished_decode_ct=15, new_prefill=[(0|44|default|-929),], req_ids=[REQ14,]
TOKEN_UPDATE: first frame token generated for req=REQ14, new_pos=747, new_len=45, token=109944, bid=15, appending to context
GENERATION DECODING: len=16, examples=[(0|51),(1|102),(2|153),(3|204),(4|255),(5|306),(6|357),(7|406),(8|455),(9|504),(10|553),(11|602),(12|651),(13|700),(14|747),(15|792),], req_ids=[REQ1,REQ3,REQ4,REQ6,REQ9,REQ0,REQ5,REQ2,REQ8,REQ11,REQ13,REQ15,REQ7,REQ12,REQ10,REQ14,]
Process Process-4:
Traceback (most recent call last):
  File "/home/st491/anaconda3/envs/server/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/st491/anaconda3/envs/server/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/mnt/e/UbuntuFiles/codes/LiteBatchQwenServer/serving/ddp_worker.py", line 262, in infer_worker_loop
    process_loop.run_until_complete(asyncio.gather(*infinite_tasks))
  File "/home/st491/anaconda3/envs/server/lib/python3.9/site-packages/nest_asyncio.py", line 99, in run_until_complete
    return f.result()
  File "/home/st491/anaconda3/envs/server/lib/python3.9/asyncio/tasks.py", line 256, in __step
    result = coro.send(None)
  File "/mnt/e/UbuntuFiles/codes/LiteBatchQwenServer/serving/ddp_worker.py", line 225, in try_submit
    logits_info = resp["logits"] # if "logits" in resp else None
KeyError: 'logits'
07/21/2024 07:27:45 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
07/21/2024 07:27:55 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
07/21/2024 07:28:05 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
07/21/2024 07:28:15 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
07/21/2024 07:28:25 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
07/21/2024 07:28:35 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
07/21/2024 07:34:47 - INFO - __main__ - cleaning process started...
07/21/2024 07:34:47 - INFO - serving.ddp_worker - DDP: python loop: data_id=0/1 thread started.
INFO:     Started server process [6316]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8081 (Press CTRL+C to quit)
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
initializing with layer-device setup: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
device -1 loading file pytorch_model-00001-of-00003.bin:   0%|          | 0/539 [00:00<?, ?it/s]device -1 loading file pytorch_model-00001-of-00003.bin:   0%|          | 1/539 [00:00<06:05,  1.47it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  16%|█▌        | 86/539 [00:00<00:03, 148.90it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  35%|███▍      | 186/539 [00:00<00:01, 318.10it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  54%|█████▍    | 291/539 [00:00<00:00, 473.31it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  70%|██████▉   | 375/539 [00:01<00:00, 549.73it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  85%|████████▍ | 457/539 [00:01<00:00, 587.98it/s]device -1 loading file pytorch_model-00001-of-00003.bin:  99%|█████████▉| 534/539 [00:01<00:00, 600.48it/s]device -1 loading file pytorch_model-00001-of-00003.bin: 100%|██████████| 539/539 [00:01<00:00, 401.97it/s]
device -1 loading file pytorch_model-00002-of-00003.bin:   0%|          | 0/861 [00:00<?, ?it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  10%|▉         | 86/861 [00:00<00:00, 844.38it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  20%|██        | 176/861 [00:00<00:00, 871.91it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  31%|███       | 266/861 [00:00<00:00, 875.24it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  41%|████      | 354/861 [00:00<00:00, 871.54it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  51%|█████▏    | 442/861 [00:00<00:00, 686.29it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  60%|█████▉    | 516/861 [00:00<00:00, 660.23it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  68%|██████▊   | 586/861 [00:00<00:00, 658.68it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  76%|███████▌  | 655/861 [00:00<00:00, 658.20it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  84%|████████▍ | 726/861 [00:01<00:00, 641.76it/s]device -1 loading file pytorch_model-00002-of-00003.bin:  92%|█████████▏| 792/861 [00:01<00:00, 640.43it/s]device -1 loading file pytorch_model-00002-of-00003.bin: 100%|█████████▉| 857/861 [00:01<00:00, 630.12it/s]device -1 loading file pytorch_model-00002-of-00003.bin: 100%|██████████| 861/861 [00:01<00:00, 688.42it/s]
device -1 loading file pytorch_model-00003-of-00003.bin:   0%|          | 0/83 [00:00<?, ?it/s]device -1 loading file pytorch_model-00003-of-00003.bin:   1%|          | 1/83 [00:00<01:07,  1.22it/s]device -1 loading file pytorch_model-00003-of-00003.bin: 100%|██████████| 83/83 [00:00<00:00, 90.25it/s]
device -1 loading lora default:   0%|          | 0/560 [00:00<?, ?it/s]device -1 loading lora default:   6%|▋         | 36/560 [00:00<00:01, 358.25it/s]device -1 loading lora default:  13%|█▎        | 75/560 [00:00<00:01, 375.07it/s]device -1 loading lora default:  21%|██        | 116/560 [00:00<00:01, 381.53it/s]device -1 loading lora default:  28%|██▊       | 156/560 [00:00<00:01, 386.69it/s]device -1 loading lora default:  35%|███▌      | 196/560 [00:00<00:00, 389.33it/s]device -1 loading lora default:  42%|████▏     | 235/560 [00:00<00:00, 381.58it/s]device -1 loading lora default:  49%|████▉     | 274/560 [00:00<00:00, 374.07it/s]device -1 loading lora default:  56%|█████▌    | 314/560 [00:00<00:00, 375.61it/s]device -1 loading lora default:  63%|██████▎   | 355/560 [00:00<00:00, 383.41it/s]device -1 loading lora default:  71%|███████   | 396/560 [00:01<00:00, 384.71it/s]device -1 loading lora default:  78%|███████▊  | 435/560 [00:01<00:00, 386.16it/s]device -1 loading lora default:  85%|████████▍ | 474/560 [00:01<00:00, 386.93it/s]device -1 loading lora default:  92%|█████████▏| 513/560 [00:01<00:00, 378.53it/s]device -1 loading lora default:  99%|█████████▊| 552/560 [00:01<00:00, 376.54it/s]device -1 loading lora default: 100%|██████████| 560/560 [00:01<00:00, 382.41it/s]
initializing cpp Qwen1.5 model, with num_layers=40, max_dynamic_bsz=16
Data parallel worker data_id=0 has layers on devices [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
python smem psm_78c20298 binded with size=2637824..
lora configs loaded:
default: r=8, modules=[k_proj,gate_proj,o_proj,v_proj,down_proj,q_proj,up_proj]
data_id 0 is using devices[0, 1)
setting up inference on data_id=0, using devices=[0, 1), num_layers=40, max_dynamic_bsz=16, max_BL=5120
device 0 initialized cublas handler
allocating kv-cache pools for data_id=0, size=[BL(5120), Hkv(40)*D(128)] * layer_num(40 in 1 stages) * 2(KV)
kv cache layer ptr: key&value separation=1048576000, layer_stride=26214400
stage with layers[0, 40) initialized the starting pointers for each layer.
initializing BatchInputPreparer, max_B=16, max_BL=5120
input preparer initialized...allocating cos & sin, max_len=5120, kv_channels=128, gpu_id=0
preparing gpu rotary cos and sin with [seq_length, channel]=[5120, 128] on device 0
data_id=0 loading all cpu weights to gpus according to device map.
offloaded param model.embed_tokens.weight to cpu
before buffer preparing
allocated gptq buffers on device 0: state[5120, 1], dq=[1, 73400320]. starting make_q4
quant weights prepared for data_id=0
new curand initializing with key=0, curandSize=256x48
### device (0): mem_free=10351MB, mem_total=24575MB
warmup prefilling...
warming up for data_id=0, lora detected=default, prefill_len=1876 ...
KV_CACHING[gpu0]: successful allocate maxlen=1896, req_id=warmup0001. Empty memory, numel=<<+9707520>>
KV_CACHING[gpu0]: successful allocate maxlen=44, req_id=warmup0002. MemoryInfo=[0,0]_[0,9707520]_<<+225280>>_[26214400]
warmup decoding...
KV_CACHING[gpu0]: free cache block=warmup0001, remaining block_ct=1
KV_CACHING[gpu0]: free cache block=warmup0002, remaining block_ct=0
warmup finished for data_id=0
loading_ct=1
<=============data parallel id 0 ready for inference.===========
07/21/2024 07:35:24 - INFO - serving.ddp_worker - DDP: data_id=0 model loaded...
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ6', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ1', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50458 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ6, queue=1, dict=1
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ0', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ7', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ2', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50468 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ1, queue=2, dict=2
INFO:     127.0.0.1:50482 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ0, queue=3, dict=3
INFO:     127.0.0.1:50474 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ7, queue=4, dict=4
INFO:     127.0.0.1:50464 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ2, queue=5, dict=5
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ4', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ3', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ8', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ9', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ5', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ11', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50490 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ4, queue=6, dict=6
INFO:     127.0.0.1:50500 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ3, queue=7, dict=7
INFO:     127.0.0.1:50514 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ8, queue=8, dict=8
INFO:     127.0.0.1:50530 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ9, queue=9, dict=9
INFO:     127.0.0.1:50532 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ5, queue=9, dict=10
INFO:     127.0.0.1:50534 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ11, queue=10, dict=11
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ10', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ13', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ12', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ15', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:28 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ14', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50540 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ10, queue=11, dict=12
INFO:     127.0.0.1:50556 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ13, queue=12, dict=13
INFO:     127.0.0.1:50562 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ12, queue=13, dict=14
INFO:     127.0.0.1:50570 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ15, queue=14, dict=15
INFO:     127.0.0.1:50574 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:28 - INFO - serving.pool_client - CLIENT: added request REQ14, queue=15, dict=16
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ6
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=1, req_id=REQ6, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ1
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=2, req_id=REQ1, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ0
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=3, req_id=REQ0, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ7
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=4, req_id=REQ7, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ2
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=5, req_id=REQ2, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ4
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=6, req_id=REQ4, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ3
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=7, req_id=REQ3, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ8
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=8, req_id=REQ8, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ9
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=9, req_id=REQ9, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ5
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=10, req_id=REQ5, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ6, queue_size=1
POOL: Added to queue: request_id=REQ1, queue_size=2
POOL: Added to queue: request_id=REQ0, queue_size=3
POOL: Added to queue: request_id=REQ7, queue_size=4
POOL: Added to queue: request_id=REQ2, queue_size=5
POOL: Added to queue: request_id=REQ4, queue_size=6
POOL: Added to queue: request_id=REQ3, queue_size=7
POOL: Added to queue: request_id=REQ8, queue_size=8
POOL: Added to queue: request_id=REQ9, queue_size=9
POOL: Added to queue: request_id=REQ5, queue07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ11
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=11, req_id=REQ11, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ10
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=12, req_id=REQ10, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ13
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=13, req_id=REQ13, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ12
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=14, req_id=REQ12, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ15
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=15, req_id=REQ15, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ14
07/21/2024 07:35:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=16, req_id=REQ14, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
_size=10
POOL: Added to queue: request_id=REQ11, queue_size=11
POOL: Added to queue: request_id=REQ10, queue_size=12
POOL: Added to queue: request_id=REQ13, queue_size=13
POOL: Added to queue: request_id=REQ12, queue_size=14
POOL: Added to queue: request_id=REQ15, queue_size=15
POOL: Added to queue: request_id=REQ14, queue_size=16
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ6. Empty memory, numel=<<+1310720>>
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ0. MemoryInfo=[0,0]_[0,1310720]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ2. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ3. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ9. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ11. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ13. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ15. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_<<+1310720>>_[26214400]
BATCHING: 8 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ6) (256,REQ0) (256,REQ2) (256,REQ3) (256,REQ9) (256,REQ11) (256,REQ13) (256,REQ15) 
GENERATION RELOADED: unfinished_decode_ct=0, new_prefill=[(0|44|default|-967),(1|88|default|-964),(2|132|default|-962),(3|176|default|-960),(4|220|default|-957),(5|264|default|-954),(6|308|default|-952),(7|352|default|-949),], req_ids=[REQ6,REQ0,REQ2,REQ3,REQ9,REQ11,REQ13,REQ15,]
TOKEN_UPDATE: first frame token generated for req=REQ6, new_pos=0, new_len=45, token=109944, bid=0, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ0, new_pos=45, new_len=45, token=109944, bid=1, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ2, new_pos=90, new_len=45, token=109944, bid=2, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ3, new_pos=135, new_len=45, token=109944, bid=3, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ9, new_pos=180, new_len=45, token=109944, bid=4, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ11, new_pos=225, new_len=45, token=109944, bid=5, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ13, new_pos=270, new_len=45, token=109944, bid=6, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ15, new_pos=315, new_len=45, token=109944, bid=7, appending to context
GENERATION DECODING: len=8, examples=[(0|45),(1|90),(2|135),(3|180),(4|225),(5|270),(6|315),(7|360),], req_ids=[REQ6,REQ0,REQ2,REQ3,REQ9,REQ11,REQ13,REQ15,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ1. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ4. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ5. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ12. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_<<+1310720>>_[26214400]
BATCHING: 4 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ1) (256,REQ4) (256,REQ5) (256,REQ12) 
GENERATION RELOADED: unfinished_decode_ct=8, new_prefill=[(0|44|default|-966),(1|88|default|-961),(2|132|default|-956),(3|176|default|-951),], req_ids=[REQ1,REQ4,REQ5,REQ12,]
TOKEN_UPDATE: first frame token generated for req=REQ1, new_pos=376, new_len=45, token=109944, bid=8, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ4, new_pos=421, new_len=45, token=109944, bid=9, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ5, new_pos=466, new_len=45, token=109944, bid=10, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ12, new_pos=511, new_len=45, token=109944, bid=11, appending to context
GENERATION DECODING: len=12, examples=[(0|47),(1|94),(2|141),(3|188),(4|235),(5|282),(6|329),(7|376),(8|421),(9|466),(10|511),(11|556),], req_ids=[REQ6,REQ0,REQ2,REQ3,REQ9,REQ11,REQ13,REQ15,REQ1,REQ4,REQ5,REQ12,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ7. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_<<+1310720>>_[26214400]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ10. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_<<+1310720>>_[26214400]
BATCHING: 2 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ7) (256,REQ10) 
GENERATION RELOADED: unfinished_decode_ct=12, new_prefill=[(0|44|default|-963),(1|88|default|-953),], req_ids=[REQ7,REQ10,]
TOKEN_UPDATE: first frame token generated for req=REQ7, new_pos=580, new_len=45, token=109944, bid=12, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ10, new_pos=625, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|49),(1|98),(2|147),(3|196),(4|245),(5|294),(6|343),(7|392),(8|439),(9|486),(10|533),(11|580),(12|625),(13|670),], req_ids=[REQ6,REQ0,REQ2,REQ3,REQ9,REQ11,REQ13,REQ15,REQ1,REQ4,REQ5,REQ12,REQ7,REQ10,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ8. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ8) 
GENERATION RELOADED: unfinished_decode_ct=14, new_prefill=[(0|44|default|-959),], req_ids=[REQ8,]
TOKEN_UPDATE: first frame token generated for req=REQ8, new_pos=698, new_len=45, token=109944, bid=14, appending to context
GENERATION DECODING: len=15, examples=[(0|51),(1|102),(2|153),(3|204),(4|255),(5|306),(6|357),(7|408),(8|457),(9|506),(10|555),(11|604),(12|651),(13|698),(14|743),], req_ids=[REQ6,REQ0,REQ2,REQ3,REQ9,REQ11,REQ13,REQ15,REQ1,REQ4,REQ5,REQ12,REQ7,REQ10,REQ8,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ14. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_[18350080,19660800]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ14) 
GENERATION RELOADED: unfinished_decode_ct=15, new_prefill=[(0|44|default|-948),], req_ids=[REQ14,]
TOKEN_UPDATE: first frame token generated for req=REQ14, new_pos=773, new_len=45, token=109944, bid=15, appending to context
GENERATION DECODING: len=16, examples=[(0|53),(1|106),(2|159),(3|212),(4|265),(5|318),(6|371),(7|424),(8|475),(9|526),(10|577),(11|628),(12|677),(13|726),(14|773),(15|818),], req_ids=[REQ6,REQ0,REQ2,REQ3,REQ9,REQ11,REQ13,REQ15,REQ1,REQ4,REQ5,REQ12,REQ7,REQ10,REQ8,REQ14,]
TOKEN_UPDATE: EOS for req=REQ13, mini_bid=6, start=948, inp/gen=44/114
KV_CACHING[gpu0]: free cache block=REQ13, remaining block_ct=15
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=13, request_id=REQ13 first/total=(0.704497/6.482361) secs, inp/rep=44/114 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3680 logits
POOL: eos hit for request_id=REQ13, resp_token_len=115, deleting from pool.
POOL: queue after cleaning REQ13 remaining res map/queue size=15/15
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ13
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ16', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50582 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ16, queue=1, dict=16
TOKEN_UPDATE: EOS for req=REQ6, mini_bid=0, start=0, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ6, remaining block_ct=14
TOKEN_UPDATE: EOS for req=REQ2, mini_bid=2, start=320, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ2, remaining block_ct=13
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=5, request_id=REQ2 first/total=(0.705249/6.585928) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ16
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=17, req_id=REQ16, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ2, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ2 remaining res map/queue size=14/14
POOL: Added to queue: request_id=REQ16, queue_size=1
TOKEN_UPDATE: EOS for req=REQ0, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ0, remaining block_ct=12
TOKEN_UPDATE: EOS for req=REQ3, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ3, remaining block_ct=11
TOKEN_UPDATE: EOS for req=REQ9, mini_bid=2, start=322, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ9, remaining block_ct=10
TOKEN_UPDATE: EOS for req=REQ11, mini_bid=3, start=483, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ11, remaining block_ct=9
TOKEN_UPDATE: EOS for req=REQ15, mini_bid=4, start=644, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ15, remaining block_ct=8
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ16. MemoryInfo=[0,0]_<<+1310720>>_[10485760]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ16) 
GENERATION RELOADED: unfinished_decode_ct=8, new_prefill=[(0|44|default|-372),], req_ids=[REQ16,]
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=1, request_id=REQ6 first/total=(0.707457/6.688662) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ2
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=3, request_id=REQ0 first/total=(0.706213/6.688301) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ6, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ6 remaining res map/queue size=14/14
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ0, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ0 remaining res map/queue size=13/13
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ17', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=7, request_id=REQ3 first/total=(0.705531/6.689791) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
INFO:     127.0.0.1:50586 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ17, queue=1, dict=16
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=9, request_id=REQ9 first/total=(0.704725/6.689713) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ17
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=18, req_id=REQ17, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ3, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ3 remaining res map/queue size=12/12
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ9, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ9 remaining res map/queue size=11/11
POOL: Added to queue: request_id=REQ17, queue_size=1
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ11, resp_token_len=118, de07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=11, request_id=REQ11 first/total=(0.704509/6.690386) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=15, request_id=REQ15 first/total=(0.703542/6.689142) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
leting from pool.
POOL: queue after cleaning REQ11 remaining res map/queue size=10/10
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ15, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ15 remaining res map/queue size=9/9
TOKEN_UPDATE: first frame token generated for req=REQ16, new_pos=1266, new_len=45, token=109944, bid=8, appending to context
GENERATION DECODING: len=9, examples=[(0|160),(1|320),(2|480),(3|640),(4|798),(5|956),(6|1112),(7|1266),(8|1311),], req_ids=[REQ1,REQ4,REQ5,REQ12,REQ7,REQ10,REQ8,REQ14,REQ16,]
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ9
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ11
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ15
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=13
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ18', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50594 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ18, queue=1, dict=14
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ19', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50598 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ19, queue=2, dict=15
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ20', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50604 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ20, queue=3, dict=16
TOKEN_UPDATE: EOS for req=REQ4, mini_bid=1, start=160, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ4, remaining block_ct=8
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ17. MemoryInfo=[0,0]_[0,1310720]_<<+1310720>>_[10485760]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ17) 
GENERATION RELOADED: unfinished_decode_ct=8, new_prefill=[(0|44|default|-265),], req_ids=[REQ17,]
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ18
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=19, req_id=REQ18, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ19
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=20, req_id=REQ19, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ18, queue_size=1
POOL: Added to queue: request_id=REQ19, queue_size=2
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=6, request_id=REQ4 first/total=(1.109003/6.791553) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ20
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=21, req_id=REQ20, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ4, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ4 remaining res map/queue size=9/9
POOL: Added to queue: request_id=REQ20, queue_size=3
TOKEN_UPDATE: first frame token generated for req=REQ17, new_pos=1159, new_len=45, token=109944, bid=8, appending to context
GENERATION DECODING: len=9, examples=[(0|161),(1|322),(2|483),(3|642),(4|801),(5|958),(6|1113),(7|1159),(8|1204),], req_ids=[REQ1,REQ5,REQ12,REQ7,REQ10,REQ8,REQ14,REQ16,REQ17,]
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ6
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ0
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ4
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=13
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ3
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=12
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ21', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50610 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ21, queue=1, dict=13
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ22', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ23', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ21
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=22, req_id=REQ21, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
INFO:     127.0.0.1:50614 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ22, queue=1, dict=14
INFO:     127.0.0.1:50624 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ22
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=23, req_id=REQ22, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ23, queue=1, dict=15
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ24', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50632 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ23
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=24, req_id=REQ23, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ24, queue=1, dict=16
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ24
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=25, req_id=REQ24, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ21, queue_size=4
POOL: Added to queue: request_id=REQ22, queue_size=5
POOL: Added to queue: request_id=REQ23, queue_size=6
POOL: Added to queue: request_id=REQ24, queue_size=7
TOKEN_UPDATE: EOS for req=REQ1, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ1, remaining block_ct=8
TOKEN_UPDATE: EOS for req=REQ5, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ5, remaining block_ct=7
TOKEN_UPDATE: EOS for req=REQ12, mini_bid=2, start=322, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ12, remaining block_ct=6
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ18. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ20. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ22. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ24. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ19. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ23. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ21. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_<<+1310720>>_[15728640]
BATCHING: 7 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ18) (256,REQ20) (256,REQ22) (256,REQ24) (256,REQ19) (256,REQ23) (256,REQ21) 
GENERATION RELOADED: unfinished_decode_ct=6, new_prefill=[(0|44|default|-174),(1|88|default|-166),(2|132|default|-60),(3|176|default|-56),(4|220|default|-172),(5|264|default|-57),(6|308|default|-63),], req_ids=[REQ18,REQ20,REQ22,REQ24,REQ19,REQ23,REQ21,]
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=2, request_id=REQ1 first/total=(1.112719/6.993503) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ1, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ1 remaining res map/queue size=15/15
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=10, request_id=REQ5 first/total=(1.10817/6.995746) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=14, request_id=REQ12 first/total=(1.107326/6.994465) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ1
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ25', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50642 - "POST /stream_chat_post HTTP/1.1" 200 OK
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ5, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ5 remaining res map/queue size=14/14
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ12, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ12 remaining res map/queue size=13/13
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ25, queue=1, dict=16
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ25
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=26, req_id=REQ25, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ5
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: reached eos for REQ12
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ26', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50650 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ26, queue=1, dict=15
07/21/2024 07:35:35 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ27', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50660 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:35 - INFO - serving.pool_client - CLIENT: added request REQ27, queue=2, dict=16
POOL: Added to queue: request_id=REQ25, queue_size=1
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ26
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=27, req_id=REQ26, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ27
07/21/2024 07:35:35 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=28, req_id=REQ27, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ26, queue_size=2
POOL: Added to queue: request_id=REQ27, queue_size=3
TOKEN_UPDATE: first frame token generated for req=REQ18, new_pos=727, new_len=45, token=109944, bid=6, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ20, new_pos=772, new_len=45, token=109944, bid=7, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ22, new_pos=817, new_len=45, token=109944, bid=8, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ24, new_pos=862, new_len=45, token=109944, bid=9, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ19, new_pos=907, new_len=45, token=109944, bid=10, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ23, new_pos=952, new_len=45, token=109944, bid=11, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ21, new_pos=997, new_len=45, token=109944, bid=12, appending to context
GENERATION DECODING: len=13, examples=[(0|160),(1|320),(2|478),(3|634),(4|681),(5|727),(6|772),(7|817),(8|862),(9|907),(10|952),(11|997),(12|1042),], req_ids=[REQ7,REQ10,REQ8,REQ14,REQ16,REQ17,REQ18,REQ20,REQ22,REQ24,REQ19,REQ23,REQ21,]
TOKEN_UPDATE: EOS for req=REQ7, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ7, remaining block_ct=12
TOKEN_UPDATE: EOS for req=REQ10, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ10, remaining block_ct=11
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ25. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ27. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ26. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_<<+1310720>>_[18350080]
BATCHING: 3 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ25) (256,REQ27) (256,REQ26) 
GENERATION RELOADED: unfinished_decode_ct=11, new_prefill=[(0|44|default|-856),(1|88|default|-753),(2|132|default|-767),], req_ids=[REQ25,REQ27,REQ26,]
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=4, request_id=REQ7 first/total=(1.312502/7.397521) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=12, request_id=REQ10 first/total=(1.310074/7.399754) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ7, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ7 remaining res map/queue size=15/15
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ10, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ10 remaining res map/queue size=14/14
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: reached eos for REQ7
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:36 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ28', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50668 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: added request REQ28, queue=1, dict=16
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ28
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=29, req_id=REQ28, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: reached eos for REQ10
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:36 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ29', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50684 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: added request REQ29, queue=1, dict=16
POOL: Added to queue: request_id=REQ28, queue_size=1
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ29
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=30, req_id=REQ29, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ29, queue_size=2
TOKEN_UPDATE: first frame token generated for req=REQ25, new_pos=744, new_len=45, token=109944, bid=11, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ27, new_pos=789, new_len=45, token=109944, bid=12, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ26, new_pos=834, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|160),(1|318),(2|367),(3|415),(4|462),(5|509),(6|556),(7|603),(8|650),(9|697),(10|744),(11|789),(12|834),(13|879),], req_ids=[REQ8,REQ14,REQ16,REQ17,REQ18,REQ20,REQ22,REQ24,REQ19,REQ23,REQ21,REQ25,REQ27,REQ26,]
TOKEN_UPDATE: EOS for req=REQ8, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ8, remaining block_ct=13
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ28. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_<<+1310720>>_[19660800]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ28) 
GENERATION RELOADED: unfinished_decode_ct=13, new_prefill=[(0|44|default|-449),], req_ids=[REQ28,]
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=8, request_id=REQ8 first/total=(1.511355/7.804151) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ8, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ8 remaining res map/queue size=14/14
TOKEN_UPDATE: first frame token generated for req=REQ28, new_pos=745, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|160),(1|211),(2|261),(3|310),(4|359),(5|408),(6|457),(7|506),(8|555),(9|604),(10|651),(11|698),(12|745),(13|790),], req_ids=[REQ14,REQ16,REQ17,REQ18,REQ20,REQ22,REQ24,REQ19,REQ23,REQ21,REQ25,REQ27,REQ26,REQ28,]
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: reached eos for REQ8
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:36 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ30', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50696 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: added request REQ30, queue=1, dict=16
TOKEN_UPDATE: EOS for req=REQ14, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ14, remaining block_ct=13
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ29. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ29) 
GENERATION RELOADED: unfinished_decode_ct=13, new_prefill=[(0|44|default|-362),], req_ids=[REQ29,]
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ30
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=31, req_id=REQ30, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=16, request_id=REQ14 first/total=(1.60904/8.004682) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: Added to queue: request_id=REQ30, queue_size=1
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ14, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ14 remaining res map/queue size=14/14
TOKEN_UPDATE: first frame token generated for req=REQ29, new_pos=656, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|53),(1|105),(2|156),(3|207),(4|258),(5|309),(6|360),(7|411),(8|462),(9|511),(10|560),(11|609),(12|656),(13|701),], req_ids=[REQ16,REQ17,REQ18,REQ20,REQ22,REQ24,REQ19,REQ23,REQ21,REQ25,REQ27,REQ26,REQ28,REQ29,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ30. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ30) 
GENERATION RELOADED: unfinished_decode_ct=14, new_prefill=[(0|44|default|-950),], req_ids=[REQ30,]
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: reached eos for REQ14
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:36 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ31', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:50710 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:36 - INFO - serving.pool_client - CLIENT: added request REQ31, queue=1, dict=16
TOKEN_UPDATE: first frame token generated for req=REQ30, new_pos=729, new_len=45, token=109944, bid=14, appending to context
GENERATION DECODING: len=15, examples=[(0|55),(1|109),(2|162),(3|215),(4|268),(5|321),(6|374),(7|427),(8|480),(9|531),(10|582),(11|633),(12|682),(13|729),(14|774),], req_ids=[REQ16,REQ17,REQ18,REQ20,REQ22,REQ24,REQ19,REQ23,REQ21,REQ25,REQ27,REQ26,REQ28,REQ29,REQ30,]
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ31
07/21/2024 07:35:36 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=32, req_id=REQ31, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ31, queue_size=1
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ31. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_[18350080,19660800]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ31) 
GENERATION RELOADED: unfinished_decode_ct=15, new_prefill=[(0|44|default|-740),], req_ids=[REQ31,]
TOKEN_UPDATE: first frame token generated for req=REQ31, new_pos=804, new_len=45, token=109944, bid=15, appending to context
GENERATION DECODING: len=16, examples=[(0|57),(1|113),(2|168),(3|223),(4|278),(5|333),(6|388),(7|443),(8|498),(9|551),(10|604),(11|657),(12|708),(13|757),(14|804),(15|849),], req_ids=[REQ16,REQ17,REQ18,REQ20,REQ22,REQ24,REQ19,REQ23,REQ21,REQ25,REQ27,REQ26,REQ28,REQ29,REQ30,REQ31,]
07/21/2024 07:35:37 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
TOKEN_UPDATE: EOS for req=REQ16, mini_bid=0, start=0, inp/gen=44/114
KV_CACHING[gpu0]: free cache block=REQ16, remaining block_ct=15
07/21/2024 07:35:41 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=17, request_id=REQ16 first/total=(0.201785/6.480714) secs, inp/rep=44/114 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3680 logits
POOL: eos hit for request_id=REQ16, resp_token_len=115, deleting from pool.
POOL: queue after cleaning REQ16 remaining res map/queue size=15/15
07/21/2024 07:35:41 - INFO - serving.pool_client - CLIENT: reached eos for REQ16
07/21/2024 07:35:41 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:41 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ32', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51488 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:41 - INFO - serving.pool_client - CLIENT: added request REQ32, queue=1, dict=16
TOKEN_UPDATE: EOS for req=REQ17, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ17, remaining block_ct=14
TOKEN_UPDATE: EOS for req=REQ22, mini_bid=3, start=481, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ22, remaining block_ct=13
TOKEN_UPDATE: EOS for req=REQ19, mini_bid=5, start=801, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ19, remaining block_ct=12
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=20, request_id=REQ19 first/total=(0.605637/6.481502) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ32
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=33, req_id=REQ32, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=18, request_id=REQ17 first/total=(0.304363/6.58185) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ19, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ19 remaining res map/queue size=14/14
POOL: Added to queue: request_id=REQ32, queue_size=1
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ17, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ17 remaining res map/queue size=13/13
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ22, resp_token_len=11707/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=23, request_id=REQ22 first/total=(0.502617/6.37819) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
, deleting from pool.
POOL: queue after cleaning REQ22 remaining res map/queue size=12/12
TOKEN_UPDATE: EOS for req=REQ18, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ18, remaining block_ct=11
TOKEN_UPDATE: EOS for req=REQ20, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ20, remaining block_ct=10
TOKEN_UPDATE: EOS for req=REQ24, mini_bid=2, start=322, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ24, remaining block_ct=9
TOKEN_UPDATE: EOS for req=REQ23, mini_bid=3, start=483, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ23, remaining block_ct=8
TOKEN_UPDATE: EOS for req=REQ21, mini_bid=4, start=644, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ21, remaining block_ct=7
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ32. MemoryInfo=[0,0]_<<+1310720>>_[11796480]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ32) 
GENERATION RELOADED: unfinished_decode_ct=7, new_prefill=[(0|44|default|-687),], req_ids=[REQ32,]
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ17
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ22
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ33', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51494 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ33, queue=1, dict=15
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ34', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51506 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ34, queue=2, dict=16
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=19, request_id=REQ18 first/total=(0.603619/6.583653) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ33
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=34, req_id=REQ33, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ34
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=35, req_id=REQ34, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=21, request_id=REQ20 first/total=(0.602136/6.583572) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ18, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ18 remaining res map/queue size=12/12
POOL: Added to queue: request_id=REQ33, queue_size=1
POOL: Added to queue: request_id=REQ34, queue_size=2
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ20, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ20 remaining res map/queue size=11/11
POOL: returning last frame 3776 logits
P07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=22, request_id=REQ21 first/total=(0.502214/6.481537) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=24, request_id=REQ23 first/total=(0.505219/6.481731) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=25, request_id=REQ24 first/total=(0.504474/6.482054) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
OOL: eos hit for request_id=REQ21, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ21 remaining res map/queue size=10/10
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ23, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ23 remaining res map/queue size=9/9
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ24, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ24 remaining res map/queue size=8/8
TOKEN_UPDATE: first frame token generated for req=REQ32, new_pos=1100, new_len=45, token=109944, bid=7, appending to context
GENERATION DECODING: len=8, examples=[(0|160),(1|320),(2|480),(3|638),(4|794),(5|948),(6|1100),(7|1145),], req_ids=[REQ25,REQ27,REQ26,REQ28,REQ29,REQ30,REQ31,REQ32,]
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ18
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ19
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ20
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=13
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=13
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ35', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51518 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ35, queue=1, dict=14
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ36', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51530 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ36, queue=2, dict=15
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ37', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51536 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ37, queue=3, dict=16
TOKEN_UPDATE: EOS for req=REQ25, mini_bid=0, start=0, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ25, remaining block_ct=7
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ33. MemoryInfo=[0,0]_[0,1310720]_<<+1310720>>_[13107200]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ33) 
GENERATION RELOADED: unfinished_decode_ct=7, new_prefill=[(0|44|default|-587),], req_ids=[REQ33,]
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ35
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=36, req_id=REQ35, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ36
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=37, req_id=REQ36, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ37
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=38, req_id=REQ37, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=26, request_id=REQ25 first/total=(0.703157/6.381475) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
POOL: Added to queue: request_id=REQ35, queue_size=2
POOL: Added to queue: request_id=REQ36, queue_size=3
POOL: Added to queue: request_id=REQ37, queue_size=4
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ25, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ25 remaining res map/queue size=8/8
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ25
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ38', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51544 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ38, queue=1, dict=16
TOKEN_UPDATE: first frame token generated for req=REQ33, new_pos=992, new_len=45, token=109944, bid=7, appending to context
GENERATION DECODING: len=8, examples=[(0|161),(1|322),(2|481),(3|638),(4|793),(5|946),(6|992),(7|1037),], req_ids=[REQ27,REQ26,REQ28,REQ29,REQ30,REQ31,REQ32,REQ33,]
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ21
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=1, dict=15
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ23
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=1, dict=14
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ24
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=1, dict=13
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ39', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51552 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ39, queue=2, dict=14
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ40', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51560 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ40, queue=3, dict=15
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ41', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51566 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ41, queue=4, dict=16
TOKEN_UPDATE: EOS for req=REQ27, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ27, remaining block_ct=7
TOKEN_UPDATE: EOS for req=REQ26, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ26, remaining block_ct=6
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ34. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ36. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_<<+1310720>>_[15728640]
BATCHING: 2 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ34) (256,REQ36) 
GENERATION RELOADED: unfinished_decode_ct=6, new_prefill=[(0|44|default|-583),(1|88|default|-478),], req_ids=[REQ34,REQ36,]
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ38
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=39, req_id=REQ38, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ39
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=40, req_id=REQ39, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ40
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=41, req_id=REQ40, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ41
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=42, req_id=REQ41, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=28, request_id=REQ27 first/total=(0.605425/6.387956) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ27
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
POOL: Added to queue: request_id=REQ38, queue_size=3
POOL: Added to queue: request_id=REQ39, queue_size=4
POOL: Added to queue: request_id=REQ40, queue_size=5
POOL: Added to queue: request_id=REQ41, queue_size=6
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ27, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ27 remaining res map/queue size=9/9
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ42', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51574 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ42, queue=1, dict=16
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=27, request_id=REQ26 first/total=(0.604214/6.483624) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ42
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=43, req_id=REQ42, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ26, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ26 remaining res map/queue size=8/8
POOL: Added to queue: request_id=REQ42, queue_size=7
TOKEN_UPDATE: first frame token generated for req=REQ34, new_pos=721, new_len=45, token=109944, bid=6, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ36, new_pos=766, new_len=45, token=109944, bid=7, appending to context
GENERATION DECODING: len=8, examples=[(0|160),(1|318),(2|474),(3|628),(4|675),(5|721),(6|766),(7|811),], req_ids=[REQ28,REQ29,REQ30,REQ31,REQ32,REQ33,REQ34,REQ36,]
TOKEN_UPDATE: EOS for req=REQ28, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ28, remaining block_ct=7
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ35. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ38. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ40. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ42. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ37. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ41. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ39. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_<<+1310720>>_[17039360]
BATCHING: 7 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ35) (256,REQ38) (256,REQ40) (256,REQ42) (256,REQ37) (256,REQ41) (256,REQ39) 
GENERATION RELOADED: unfinished_decode_ct=7, new_prefill=[(0|44|default|-479),(1|88|default|-371),(2|132|default|-366),(3|176|default|-281),(4|220|default|-475),(5|264|default|-365),(6|308|default|-369),], req_ids=[REQ35,REQ38,REQ40,REQ42,REQ37,REQ41,REQ39,]
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=29, request_id=REQ28 first/total=(0.401668/6.283182) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ26
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ28, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ28 remaining res map/queue size=14/14
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ43', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51580 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ43, queue=1, dict=16
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ43
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=44, req_id=REQ43, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ43, queue_size=1
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: reached eos for REQ28
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:42 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ44', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51584 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:42 - INFO - serving.pool_client - CLIENT: added request REQ44, queue=1, dict=16
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ44
07/21/2024 07:35:42 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=45, req_id=REQ44, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ44, queue_size=2
TOKEN_UPDATE: first frame token generated for req=REQ35, new_pos=665, new_len=45, token=109944, bid=7, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ38, new_pos=710, new_len=45, token=109944, bid=8, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ40, new_pos=755, new_len=45, token=109944, bid=9, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ42, new_pos=800, new_len=45, token=109944, bid=10, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ37, new_pos=845, new_len=45, token=109944, bid=11, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ41, new_pos=890, new_len=45, token=109944, bid=12, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ39, new_pos=935, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|160),(1|318),(2|474),(3|523),(4|571),(5|618),(6|665),(7|710),(8|755),(9|800),(10|845),(11|890),(12|935),(13|980),], req_ids=[REQ29,REQ30,REQ31,REQ32,REQ33,REQ34,REQ36,REQ35,REQ38,REQ40,REQ42,REQ37,REQ41,REQ39,]
TOKEN_UPDATE: EOS for req=REQ29, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ29, remaining block_ct=13
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ43. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_<<+1310720>>_[18350080]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ43) 
GENERATION RELOADED: unfinished_decode_ct=13, new_prefill=[(0|44|default|-62),], req_ids=[REQ43,]
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=30, request_id=REQ29 first/total=(0.505593/6.686634) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ29, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ29 remaining res map/queue size=14/14
TOKEN_UPDATE: first frame token generated for req=REQ43, new_pos=846, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|160),(1|318),(2|369),(3|419),(4|468),(5|517),(6|564),(7|611),(8|658),(9|705),(10|752),(11|799),(12|846),(13|891),], req_ids=[REQ30,REQ31,REQ32,REQ33,REQ34,REQ36,REQ35,REQ38,REQ40,REQ42,REQ37,REQ41,REQ39,REQ43,]
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: reached eos for REQ29
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:43 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ45', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51600 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: added request REQ45, queue=1, dict=16
TOKEN_UPDATE: EOS for req=REQ30, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ30, remaining block_ct=13
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ44. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_<<+1310720>>_[19660800]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ44) 
GENERATION RELOADED: unfinished_decode_ct=13, new_prefill=[(0|44|default|-958),], req_ids=[REQ44,]
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ45
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=46, req_id=REQ45, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=31, request_id=REQ30 first/total=(0.301382/6.484015) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: Added to queue: request_id=REQ45, queue_size=1
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ30, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ30 remaining res map/queue size=14/14
TOKEN_UPDATE: first frame token generated for req=REQ44, new_pos=757, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|160),(1|213),(2|265),(3|316),(4|367),(5|416),(6|465),(7|514),(8|563),(9|612),(10|661),(11|710),(12|757),(13|802),], req_ids=[REQ31,REQ32,REQ33,REQ34,REQ36,REQ35,REQ38,REQ40,REQ42,REQ37,REQ41,REQ39,REQ43,REQ44,]
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: reached eos for REQ30
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:43 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ46', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51616 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: added request REQ46, queue=1, dict=16
TOKEN_UPDATE: EOS for req=REQ31, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ31, remaining block_ct=13
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ45. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ45) 
GENERATION RELOADED: unfinished_decode_ct=13, new_prefill=[(0|44|default|-471),], req_ids=[REQ45,]
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ46
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=47, req_id=REQ46, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ46, queue_size=1
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=32, request_id=REQ31 first/total=(0.301478/6.388206) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: reached eos for REQ31
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:43 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ47', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:51618 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:43 - INFO - serving.pool_client - CLIENT: added request REQ47, queue=1, dict=16
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ31, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ31 remaining res map/queue size=14/14
TOKEN_UPDATE: first frame token generated for req=REQ45, new_pos=668, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|55),(1|109),(2|162),(3|215),(4|266),(5|317),(6|368),(7|419),(8|470),(9|521),(10|572),(11|621),(12|668),(13|713),], req_ids=[REQ32,REQ33,REQ34,REQ36,REQ35,REQ38,REQ40,REQ42,REQ37,REQ41,REQ39,REQ43,REQ44,REQ45,]
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ47
07/21/2024 07:35:43 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=48, req_id=REQ47, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ47, queue_size=2
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ46. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ46) 
GENERATION RELOADED: unfinished_decode_ct=14, new_prefill=[(0|44|default|-362),], req_ids=[REQ46,]
TOKEN_UPDATE: first frame token generated for req=REQ46, new_pos=741, new_len=45, token=109944, bid=14, appending to context
GENERATION DECODING: len=15, examples=[(0|57),(1|113),(2|168),(3|223),(4|276),(5|329),(6|382),(7|435),(8|488),(9|541),(10|594),(11|645),(12|694),(13|741),(14|786),], req_ids=[REQ32,REQ33,REQ34,REQ36,REQ35,REQ38,REQ40,REQ42,REQ37,REQ41,REQ39,REQ43,REQ44,REQ45,REQ46,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ47. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_[18350080,19660800]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ47) 
GENERATION RELOADED: unfinished_decode_ct=15, new_prefill=[(0|44|default|-249),], req_ids=[REQ47,]
TOKEN_UPDATE: first frame token generated for req=REQ47, new_pos=816, new_len=45, token=109944, bid=15, appending to context
GENERATION DECODING: len=16, examples=[(0|59),(1|117),(2|174),(3|231),(4|286),(5|341),(6|396),(7|451),(8|506),(9|561),(10|616),(11|669),(12|720),(13|769),(14|816),(15|861),], req_ids=[REQ32,REQ33,REQ34,REQ36,REQ35,REQ38,REQ40,REQ42,REQ37,REQ41,REQ39,REQ43,REQ44,REQ45,REQ46,REQ47,]
07/21/2024 07:35:47 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
TOKEN_UPDATE: EOS for req=REQ32, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ32, remaining block_ct=15
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=33, request_id=REQ32 first/total=(0.200459/6.486886) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ32, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ32 remaining res map/queue size=15/15
TOKEN_UPDATE: EOS for req=REQ33, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ33, remaining block_ct=14
TOKEN_UPDATE: EOS for req=REQ37, mini_bid=7, start=1113, inp/gen=44/114
KV_CACHING[gpu0]: free cache block=REQ37, remaining block_ct=13
TOKEN_UPDATE: EOS for req=REQ34, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ34, remaining block_ct=12
TOKEN_UPDATE: EOS for req=REQ36, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ36, remaining block_ct=11
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=34, request_id=REQ33 first/total=(0.301799/6.489401) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=35, request_id=REQ34 first/total=(0.403239/6.488362) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ33, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ33 remaining res map/queue size=14/14
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ34, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ34 remaining res map/queue size=13/13
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ36, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ307/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=37, request_id=REQ36 first/total=(0.300801/6.385541) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=38, request_id=REQ37 first/total=(0.704066/6.384101) secs, inp/rep=44/114 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
6 remaining res map/queue size=12/12
POOL: returning last frame 3680 logits
POOL: eos hit for request_id=REQ37, resp_token_len=115, deleting from pool.
POOL: queue after cleaning REQ37 remaining res map/queue size=11/11
TOKEN_UPDATE: EOS for req=REQ42, mini_bid=3, start=480, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ42, remaining block_ct=10
TOKEN_UPDATE: EOS for req=REQ39, mini_bid=5, start=800, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ39, remaining block_ct=9
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ32
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ36
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ37
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=13
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=13
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=13
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ48', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52874 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ48, queue=1, dict=14
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ49', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52880 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ49, queue=2, dict=15
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ50', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52886 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ50, queue=3, dict=16
TOKEN_UPDATE: EOS for req=REQ35, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ35, remaining block_ct=8
TOKEN_UPDATE: EOS for req=REQ38, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ38, remaining block_ct=7
TOKEN_UPDATE: EOS for req=REQ40, mini_bid=2, start=322, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ40, remaining block_ct=6
TOKEN_UPDATE: EOS for req=REQ41, mini_bid=3, start=483, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ41, remaining block_ct=5
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ48
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=49, req_id=REQ48, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ48, queue_size=1
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ49
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=50, req_id=REQ49, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ49, queue_size=2
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=43, request_id=REQ42 first/total=(0.502494/6.288168) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ50
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=51, req_id=REQ50, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=36, request_id=REQ35 first/total=(0.703901/6.492212) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ42, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ42 remaining res map/queue size=10/10
POOL: Added to queue: request_id=REQ50, queue_size=3
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ35, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ35 remaining res map/queue size=9/9
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ38, resp_token_len=118, 07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=39, request_id=REQ38 first/total=(0.602551/6.385968) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=40, request_id=REQ39 first/total=(0.602335/6.386005) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=41, request_id=REQ40 first/total=(0.606374/6.385299) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
deleting from pool.
POOL: queue after cleaning REQ38 remaining res map/queue size=8/8
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ39, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ39 remaining res map/queue size=7/7
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ40, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ40 remaining res map/queue size=6/6
POOL: returning last frame 3776 logits
POOL: eos hit for request07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=42, request_id=REQ41 first/total=(0.605273/6.384993) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
_id=REQ41, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ41 remaining res map/queue size=5/5
TOKEN_UPDATE: EOS for req=REQ43, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ43, remaining block_ct=4
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ48. MemoryInfo=[0,0]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ50. MemoryInfo=[0,0]_[0,1310720]_<<+1310720>>_[15728640]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ49. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_<<+1310720>>_[15728640]
BATCHING: 3 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ48) (256,REQ50) (256,REQ49) 
GENERATION RELOADED: unfinished_decode_ct=4, new_prefill=[(0|44|default|-994),(1|88|default|-988),(2|132|default|-993),], req_ids=[REQ48,REQ50,REQ49,]
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ39
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ40
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ33
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ34
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ41
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=11
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=11
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=11
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ51', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ52', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52900 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ51, queue=1, dict=12
INFO:     127.0.0.1:52902 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ52, queue=2, dict=13
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ53', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52906 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ53, queue=3, dict=14
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ54', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ55', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52912 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ54, queue=4, dict=15
INFO:     127.0.0.1:52924 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ55, queue=5, dict=16
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ42
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=5, dict=15
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ56', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52934 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ56, queue=6, dict=16
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ51
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=52, req_id=REQ51, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ52
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=53, req_id=REQ52, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ53
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=54, req_id=REQ53, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ54
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=55, req_id=REQ54, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ55
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=56, req_id=REQ55, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ56
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=57, req_id=REQ56, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=44, request_id=REQ43 first/total=(0.501567/6.185327) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: Added to queue: request_id=REQ51, queue_size=1
POOL: Added to queue: request_id=REQ52, queue_size=2
POOL: Added to queue: request_id=REQ53, queue_size=3
POOL: Added to queue: request_id=REQ54, queue_size=4
POOL: Added to queue: request_id=REQ55, queue_size=5
POOL: Added to queue: request_id=REQ56, queue_size=6
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ43, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ43 remaining res map/queue size=7/7
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ35
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ57', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52936 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ57, queue=1, dict=16
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ38
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=1, dict=15
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ58', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52938 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ58, queue=2, dict=16
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ57
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=58, req_id=REQ57, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ58
07/21/2024 07:35:48 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=59, req_id=REQ58, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ57, queue_size=7
POOL: Added to queue: request_id=REQ58, queue_size=8
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: reached eos for REQ43
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:48 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ59', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52942 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:48 - INFO - serving.pool_client - CLIENT: added request REQ59, queue=1, dict=16
07/21/2024 07:35:49 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ59
07/21/2024 07:35:49 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=60, req_id=REQ59, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ59, queue_size=9
TOKEN_UPDATE: first frame token generated for req=REQ48, new_pos=628, new_len=45, token=109944, bid=4, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ50, new_pos=673, new_len=45, token=109944, bid=5, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ49, new_pos=718, new_len=45, token=109944, bid=6, appending to context
GENERATION DECODING: len=7, examples=[(0|160),(1|318),(2|474),(3|628),(4|673),(5|718),(6|763),], req_ids=[REQ44,REQ45,REQ46,REQ47,REQ48,REQ50,REQ49,]
TOKEN_UPDATE: EOS for req=REQ44, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ44, remaining block_ct=6
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ51. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ53. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ55. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ57. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ59. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ52. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_<<+1310720>>_[17039360]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ56. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_<<+1310720>>_[17039360]
BATCHING: 7 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ51) (256,REQ53) (256,REQ55) (256,REQ57) (256,REQ59) (256,REQ52) (256,REQ56) 
GENERATION RELOADED: unfinished_decode_ct=6, new_prefill=[(0|44|default|-885),(1|88|default|-882),(2|132|default|-878),(3|176|default|-773),(4|220|default|-669),(5|264|default|-883),(6|308|default|-877),], req_ids=[REQ51,REQ53,REQ55,REQ57,REQ59,REQ52,REQ56,]
07/21/2024 07:35:49 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=45, request_id=REQ44 first/total=(0.603474/6.389596) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:49 - INFO - serving.pool_client - CLIENT: reached eos for REQ44
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ44, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ44 remaining res map/queue size=13/13
07/21/2024 07:35:49 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:49 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ60', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52950 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:49 - INFO - serving.pool_client - CLIENT: added request REQ60, queue=1, dict=16
07/21/2024 07:35:49 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ60
07/21/2024 07:35:49 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=61, req_id=REQ60, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ60, queue_size=3
TOKEN_UPDATE: first frame token generated for req=REQ51, new_pos=615, new_len=45, token=109944, bid=6, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ53, new_pos=660, new_len=45, token=109944, bid=7, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ55, new_pos=705, new_len=45, token=109944, bid=8, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ57, new_pos=750, new_len=45, token=109944, bid=9, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ59, new_pos=795, new_len=45, token=109944, bid=10, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ52, new_pos=840, new_len=45, token=109944, bid=11, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ56, new_pos=885, new_len=45, token=109944, bid=12, appending to context
GENERATION DECODING: len=13, examples=[(0|160),(1|318),(2|474),(3|521),(4|568),(5|615),(6|660),(7|705),(8|750),(9|795),(10|840),(11|885),(12|930),], req_ids=[REQ45,REQ46,REQ47,REQ48,REQ50,REQ49,REQ51,REQ53,REQ55,REQ57,REQ59,REQ52,REQ56,]
TOKEN_UPDATE: EOS for req=REQ45, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ45, remaining block_ct=12
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ54. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ60. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ58. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_<<+1310720>>_[18350080]
BATCHING: 3 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ54) (256,REQ60) (256,REQ58) 
GENERATION RELOADED: unfinished_decode_ct=12, new_prefill=[(0|44|default|-880),(1|88|default|-466),(2|132|default|-772),], req_ids=[REQ54,REQ60,REQ58,]
07/21/2024 07:35:49 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=46, request_id=REQ45 first/total=(0.300816/6.392485) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ45, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ45 remaining res map/queue size=15/15
07/21/2024 07:35:49 - INFO - serving.pool_client - CLIENT: reached eos for REQ45
07/21/2024 07:35:49 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:49 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ61', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52960 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:49 - INFO - serving.pool_client - CLIENT: added request REQ61, queue=1, dict=16
07/21/2024 07:35:49 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ61
07/21/2024 07:35:49 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=62, req_id=REQ61, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ61, queue_size=1
TOKEN_UPDATE: first frame token generated for req=REQ54, new_pos=794, new_len=45, token=109944, bid=12, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ60, new_pos=839, new_len=45, token=109944, bid=13, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ58, new_pos=884, new_len=45, token=109944, bid=14, appending to context
GENERATION DECODING: len=15, examples=[(0|160),(1|318),(2|367),(3|416),(4|465),(5|512),(6|559),(7|606),(8|653),(9|700),(10|747),(11|794),(12|839),(13|884),(14|929),], req_ids=[REQ46,REQ47,REQ48,REQ50,REQ49,REQ51,REQ53,REQ55,REQ57,REQ59,REQ52,REQ56,REQ54,REQ60,REQ58,]
TOKEN_UPDATE: EOS for req=REQ46, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ46, remaining block_ct=14
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ61. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_<<+1310720>>_[19660800]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ61) 
GENERATION RELOADED: unfinished_decode_ct=14, new_prefill=[(0|44|default|-874),], req_ids=[REQ61,]
07/21/2024 07:35:50 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=47, request_id=REQ46 first/total=(0.401281/6.692273) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ46, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ46 remaining res map/queue size=15/15
TOKEN_UPDATE: first frame token generated for req=REQ61, new_pos=797, new_len=45, token=109944, bid=14, appending to context
GENERATION DECODING: len=15, examples=[(0|160),(1|211),(2|262),(3|313),(4|362),(5|411),(6|460),(7|509),(8|558),(9|607),(10|656),(11|703),(12|750),(13|797),(14|842),], req_ids=[REQ47,REQ48,REQ50,REQ49,REQ51,REQ53,REQ55,REQ57,REQ59,REQ52,REQ56,REQ54,REQ60,REQ58,REQ61,]
07/21/2024 07:35:50 - INFO - serving.pool_client - CLIENT: reached eos for REQ46
07/21/2024 07:35:50 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:50 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ62', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52976 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:50 - INFO - serving.pool_client - CLIENT: added request REQ62, queue=1, dict=16
07/21/2024 07:35:50 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ62
07/21/2024 07:35:50 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=63, req_id=REQ62, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ62, queue_size=1
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ62. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_<<+1310720>>_[19660800]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ62) 
GENERATION RELOADED: unfinished_decode_ct=15, new_prefill=[(0|44|default|-465),], req_ids=[REQ62,]
TOKEN_UPDATE: first frame token generated for req=REQ62, new_pos=917, new_len=45, token=109944, bid=15, appending to context
GENERATION DECODING: len=16, examples=[(0|165),(1|221),(2|277),(3|333),(4|387),(5|441),(6|495),(7|549),(8|603),(9|657),(10|711),(11|763),(12|815),(13|867),(14|917),(15|962),], req_ids=[REQ47,REQ48,REQ50,REQ49,REQ51,REQ53,REQ55,REQ57,REQ59,REQ52,REQ56,REQ54,REQ60,REQ58,REQ61,REQ62,]
TOKEN_UPDATE: EOS for req=REQ47, mini_bid=0, start=0, inp/gen=44/123
KV_CACHING[gpu0]: free cache block=REQ47, remaining block_ct=15
07/21/2024 07:35:50 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=48, request_id=REQ47 first/total=(0.400815/7.100525) secs, inp/rep=44/123 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项。\n4. 聊天互动：进行日常对话，提供情感支持或娱乐。\n5. 语言翻译：翻译文本或口语，支持多种语言。\n6. 娱乐功能：讲笑话、讲故事、播放音乐等。\n\n如果你有任何具体问题或需要帮助，请随时告诉我。
POOL: returning last frame 3968 logits
POOL: eos hit for request_id=REQ47, resp_token_len=124, deleting from pool.
POOL: queue after cleaning REQ47 remaining res map/queue size=15/15
07/21/2024 07:35:50 - INFO - serving.pool_client - CLIENT: reached eos for REQ47
07/21/2024 07:35:50 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:50 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ63', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52978 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:50 - INFO - serving.pool_client - CLIENT: added request REQ63, queue=1, dict=16
07/21/2024 07:35:50 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ63
07/21/2024 07:35:50 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=64, req_id=REQ63, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ63, queue_size=1
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ63. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_[18350080,19660800]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ63) 
GENERATION RELOADED: unfinished_decode_ct=15, new_prefill=[(0|44|default|-44),], req_ids=[REQ63,]
TOKEN_UPDATE: first frame token generated for req=REQ63, new_pos=887, new_len=45, token=109944, bid=15, appending to context
GENERATION DECODING: len=16, examples=[(0|62),(1|124),(2|186),(3|246),(4|306),(5|366),(6|426),(7|486),(8|546),(9|606),(10|664),(11|722),(12|780),(13|836),(14|887),(15|932),], req_ids=[REQ48,REQ50,REQ49,REQ51,REQ53,REQ55,REQ57,REQ59,REQ52,REQ56,REQ54,REQ60,REQ58,REQ61,REQ62,REQ63,]
TOKEN_UPDATE: EOS for req=REQ55, mini_bid=5, start=796, inp/gen=44/114
KV_CACHING[gpu0]: free cache block=REQ55, remaining block_ct=15
TOKEN_UPDATE: EOS for req=REQ56, mini_bid=9, start=1428, inp/gen=44/114
KV_CACHING[gpu0]: free cache block=REQ56, remaining block_ct=14
TOKEN_UPDATE: EOS for req=REQ48, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ48, remaining block_ct=13
TOKEN_UPDATE: EOS for req=REQ50, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ50, remaining block_ct=12
TOKEN_UPDATE: EOS for req=REQ49, mini_bid=2, start=322, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ49, remaining block_ct=11
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=49, request_id=REQ48 first/total=(0.40196/6.695191) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=50, request_id=REQ49 first/total=(0.402236/6.696114) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ48, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ48 remaining res map/queue size=15/15
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ49, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ49 remaining res map/queue size=14/14
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ50, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ507/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=51, request_id=REQ50 first/total=(0.402003/6.69365) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=56, request_id=REQ55 first/total=(0.704796/6.590752) secs, inp/rep=44/114 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=57, request_id=REQ56 first/total=(0.703856/6.590629) secs, inp/rep=44/114 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ56
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ64', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52982 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ64, queue=1, dict=16
0 remaining res map/queue size=13/13
POOL: returning last frame 3680 logits
POOL: eos hit for request_id=REQ55, resp_token_len=115, deleting from pool.
POOL: queue after cleaning REQ55 remaining res map/queue size=12/12
POOL: returning last frame 3680 logits
POOL: eos hit for request_id=REQ56, resp_token_len=115, deleting from pool.
POOL: queue after cleaning REQ56 remaining res map/queue size=11/11
TOKEN_UPDATE: EOS for req=REQ59, mini_bid=3, start=480, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ59, remaining block_ct=10
TOKEN_UPDATE: EOS for req=REQ51, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ51, remaining block_ct=9
TOKEN_UPDATE: EOS for req=REQ53, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ53, remaining block_ct=8
TOKEN_UPDATE: EOS for req=REQ57, mini_bid=2, start=322, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ57, remaining block_ct=7
TOKEN_UPDATE: EOS for req=REQ52, mini_bid=3, start=483, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ52, remaining block_ct=6
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ64
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=65, req_id=REQ64, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=52, request_id=REQ51 first/total=(0.705122/6.693561) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: Added to queue: request_id=REQ64, queue_size=1
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ51, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ51 remaining res map/queue size=10/10
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ52, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ52 remaining res map/queue size=9/9
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=53, request_id=REQ52 first/total=(0.704111/6.693741) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=54, request_id=REQ53 first/total=(0.704393/6.694418) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=58, request_id=REQ57 first/total=(0.602615/6.589308) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ53, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ53 remaining res map/queue size=8/8
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ57, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ57 remaining res map/queue size=7/7
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ59, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ59 re07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=60, request_id=REQ59 first/total=(0.502889/6.487234) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ57
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ48
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ49
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ50
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=12
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=12
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=12
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=12
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ65', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:52984 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ65, queue=1, dict=13
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ67', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53000 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ67, queue=2, dict=14
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ66', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53016 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ66, queue=3, dict=15
maining res map/queue size=6/6
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ68', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
TOKEN_UPDATE: EOS for req=REQ60, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ60, remaining block_ct=5
TOKEN_UPDATE: EOS for req=REQ58, mini_bid=2, start=322, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ58, remaining block_ct=4
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ64. MemoryInfo=[0,0]_<<+1310720>>_[13107200]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ64) 
GENERATION RELOADED: unfinished_decode_ct=4, new_prefill=[(0|44|default|-194),], req_ids=[REQ64,]
INFO:     127.0.0.1:53026 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ68, queue=4, dict=16
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ51
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ52
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ53
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=4, dict=13
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=4, dict=13
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=4, dict=13
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ65
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=66, req_id=REQ65, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ55
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ67
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=2, dict=12
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=67, req_id=REQ67, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ69', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53028 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ66
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=68, req_id=REQ66, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ69, queue=2, dict=13
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ70', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ68
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=69, req_id=REQ68, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
INFO:     127.0.0.1:53044 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ69
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ70, queue=1, dict=14
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=70, req_id=REQ69, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ71', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ72', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53056 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ70
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ71, queue=1, dict=15
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=71, req_id=REQ70, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
INFO:     127.0.0.1:53064 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ71
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=72, req_id=REQ71, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ72, queue=1, dict=16
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ72
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=73, req_id=REQ72, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ65, queue_size=1
POOL: Added to queue: request_id=REQ67, queue_size=2
POOL: Added to queue: request_id=REQ66, queue_size=3
POOL: Added to queue: request_id=REQ68, queue_size=4
POOL: Added to queue: request_id=REQ69, queue_size=5
POOL: Added to queue: request_id=REQ70, queue_size=6
POOL: Added to queue: request_id=REQ71, queue_size=7
POOL: Added to queue: request_id=REQ72, queue_size=8
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ58, resp_token_le07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ59
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=59, request_id=REQ58 first/total=(1.005561/6.695387) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=61, request_id=REQ60 first/total=(0.70333/6.391615) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ73', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53074 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ73, queue=1, dict=16
n=118, deleting from pool.
POOL: queue after cleaning REQ58 remaining res map/queue size=6/6
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ60, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ60 remaining res map/queue size=5/5
TOKEN_UPDATE: first frame token generated for req=REQ64, new_pos=626, new_len=45, token=109944, bid=4, appending to context
GENERATION DECODING: len=5, examples=[(0|162),(1|322),(2|477),(3|626),(4|671),], req_ids=[REQ54,REQ61,REQ62,REQ63,REQ64,]
TOKEN_UPDATE: EOS for req=REQ54, mini_bid=0, start=0, inp/gen=44/119
KV_CACHING[gpu0]: free cache block=REQ54, remaining block_ct=4
TOKEN_UPDATE: EOS for req=REQ61, mini_bid=1, start=163, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ61, remaining block_ct=3
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ65. MemoryInfo=[0,0]_[0,1310720]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ66. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ69. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ71. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_<<+1310720>>_[18350080]
BATCHING: 4 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ65) (256,REQ66) (256,REQ69) (256,REQ71) 
GENERATION RELOADED: unfinished_decode_ct=3, new_prefill=[(0|44|default|-91),(1|88|default|-86),(2|132|default|-82),(3|176|default|-78),], req_ids=[REQ65,REQ66,REQ69,REQ71,]
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=62, request_id=REQ61 first/total=(0.300913/5.887441) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ73
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=74, req_id=REQ73, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=55, request_id=REQ54 first/total=(1.107129/6.900202) secs, inp/rep=44/119 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ61, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ61 remaining res map/queue size=8/8
POOL: Added to queue: request_id=REQ73, queue_size=5
POOL: returning last frame 3840 logits
POOL: eos hit for request_id=REQ54, resp_token_len=120, deleting from pool.
POOL: queue after cleaning REQ54 remaining res map/queue size=7/7
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ58
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ74', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53088 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ74, queue=1, dict=16
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ60
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=1, dict=15
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ54
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=1, dict=14
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ75', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53102 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ75, queue=2, dict=15
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ76', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53104 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ76, queue=3, dict=16
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ74
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=75, req_id=REQ74, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: reached eos for REQ61
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: cleaned queue=2, dict=15
07/21/2024 07:35:55 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ77', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ75
INFO:     127.0.0.1:53114 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=76, req_id=REQ75, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.pool_client - CLIENT: added request REQ77, queue=1, dict=16
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ76
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=77, req_id=REQ76, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ77
07/21/2024 07:35:55 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=78, req_id=REQ77, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ74, queue_size=6
POOL: Added to queue: request_id=REQ75, queue_size=7
POOL: Added to queue: request_id=REQ76, queue_size=8
POOL: Added to queue: request_id=REQ77, queue_size=9
TOKEN_UPDATE: first frame token generated for req=REQ65, new_pos=355, new_len=45, token=109944, bid=3, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ66, new_pos=400, new_len=45, token=109944, bid=4, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ69, new_pos=445, new_len=45, token=109944, bid=5, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ71, new_pos=490, new_len=45, token=109944, bid=6, appending to context
GENERATION DECODING: len=7, examples=[(0|157),(1|308),(2|355),(3|400),(4|445),(5|490),(6|535),], req_ids=[REQ62,REQ63,REQ64,REQ65,REQ66,REQ69,REQ71,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ67. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ70. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ73. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ75. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ77. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ68. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_<<+1310720>>_[18350080]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ74. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_<<+1310720>>_[18350080]
BATCHING: 7 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ67) (256,REQ70) (256,REQ73) (256,REQ75) (256,REQ77) (256,REQ68) (256,REQ74) 
GENERATION RELOADED: unfinished_decode_ct=7, new_prefill=[(0|44|default|-89),(1|88|default|-79),(2|132|default|-984),(3|176|default|-871),(4|220|default|-868),(5|264|default|-84),(6|308|default|-876),], req_ids=[REQ67,REQ70,REQ73,REQ75,REQ77,REQ68,REQ74,]
TOKEN_UPDATE: first frame token generated for req=REQ67, new_pos=549, new_len=45, token=109944, bid=7, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ70, new_pos=594, new_len=45, token=109944, bid=8, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ73, new_pos=639, new_len=45, token=109944, bid=9, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ75, new_pos=684, new_len=45, token=109944, bid=10, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ77, new_pos=729, new_len=45, token=109944, bid=11, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ68, new_pos=774, new_len=45, token=109944, bid=12, appending to context
TOKEN_UPDATE: first frame token generated for req=REQ74, new_pos=819, new_len=45, token=109944, bid=13, appending to context
GENERATION DECODING: len=14, examples=[(0|159),(1|312),(2|361),(3|408),(4|455),(5|502),(6|549),(7|594),(8|639),(9|684),(10|729),(11|774),(12|819),(13|864),], req_ids=[REQ62,REQ63,REQ64,REQ65,REQ66,REQ69,REQ71,REQ67,REQ70,REQ73,REQ75,REQ77,REQ68,REQ74,]
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ72. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_<<+1310720>>_[18350080]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ72) 
GENERATION RELOADED: unfinished_decode_ct=14, new_prefill=[(0|44|default|-76),], req_ids=[REQ72,]
TOKEN_UPDATE: first frame token generated for req=REQ72, new_pos=892, new_len=45, token=109944, bid=14, appending to context
GENERATION DECODING: len=15, examples=[(0|161),(1|316),(2|367),(3|416),(4|465),(5|514),(6|563),(7|610),(8|657),(9|704),(10|751),(11|798),(12|845),(13|892),(14|937),], req_ids=[REQ62,REQ63,REQ64,REQ65,REQ66,REQ69,REQ71,REQ67,REQ70,REQ73,REQ75,REQ77,REQ68,REQ74,REQ72,]
TOKEN_UPDATE: EOS for req=REQ62, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ62, remaining block_ct=14
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ76. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_<<+1310720>>_[19660800]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ76) 
GENERATION RELOADED: unfinished_decode_ct=14, new_prefill=[(0|44|default|-869),], req_ids=[REQ76,]
07/21/2024 07:35:56 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=63, request_id=REQ62 first/total=(0.200618/6.497622) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ62, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ62 remaining res map/queue size=15/15
TOKEN_UPDATE: first frame token generated for req=REQ76, new_pos=790, new_len=45, token=109944, bid=14, appending to context
GENERATION DECODING: len=15, examples=[(0|156),(1|208),(2|258),(3|308),(4|358),(5|408),(6|456),(7|504),(8|552),(9|600),(10|648),(11|696),(12|744),(13|790),(14|835),], req_ids=[REQ63,REQ64,REQ65,REQ66,REQ69,REQ71,REQ67,REQ70,REQ73,REQ75,REQ77,REQ68,REQ74,REQ72,REQ76,]
07/21/2024 07:35:56 - INFO - serving.pool_client - CLIENT: reached eos for REQ62
07/21/2024 07:35:56 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:56 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ78', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53116 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:56 - INFO - serving.pool_client - CLIENT: added request REQ78, queue=1, dict=16
07/21/2024 07:35:56 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ78
07/21/2024 07:35:56 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=79, req_id=REQ78, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ78, queue_size=1
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ78. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_<<+1310720>>_[19660800]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ78) 
GENERATION RELOADED: unfinished_decode_ct=15, new_prefill=[(0|44|default|-865),], req_ids=[REQ78,]
TOKEN_UPDATE: first frame token generated for req=REQ78, new_pos=910, new_len=45, token=109944, bid=15, appending to context
GENERATION DECODING: len=16, examples=[(0|161),(1|218),(2|273),(3|328),(4|383),(5|438),(6|491),(7|544),(8|597),(9|650),(10|703),(11|756),(12|809),(13|860),(14|910),(15|955),], req_ids=[REQ63,REQ64,REQ65,REQ66,REQ69,REQ71,REQ67,REQ70,REQ73,REQ75,REQ77,REQ68,REQ74,REQ72,REQ76,REQ78,]
TOKEN_UPDATE: EOS for req=REQ63, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ63, remaining block_ct=15
07/21/2024 07:35:57 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=64, request_id=REQ63 first/total=(0.201027/6.489009) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ63, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ63 remaining res map/queue size=15/15
07/21/2024 07:35:57 - INFO - serving.pool_client - CLIENT: reached eos for REQ63
07/21/2024 07:35:57 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=15
07/21/2024 07:35:57 - INFO - serving.app - running until complete request json:{'query': '你可以做什么？', 'history': [['你好', '你好，我是小PAI，是人工智能机器人。']], 'request_id': 'REQ79', 'gen_kwargs': {'max_length': 256, 'temperature': 0.01, 'adapter_name': 'default', 'return_logits': True}}
INFO:     127.0.0.1:53130 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:35:57 - INFO - serving.pool_client - CLIENT: added request REQ79, queue=1, dict=16
07/21/2024 07:35:57 - INFO - serving.ddp_worker - DDP0: setting lora to default after REQ79
07/21/2024 07:35:57 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=80, req_id=REQ79, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'max_length': 256}, role=user, hist_len=2, query=你可以做什么？
POOL: Added to queue: request_id=REQ79, queue_size=1
KV_CACHING[gpu0]: successful allocate maxlen=256, req_id=REQ79. MemoryInfo=[0,0]_[0,1310720]_[1310720,2621440]_[2621440,3932160]_[3932160,5242880]_[5242880,6553600]_[6553600,7864320]_[7864320,9175040]_[9175040,10485760]_[10485760,11796480]_[11796480,13107200]_[13107200,14417920]_[14417920,15728640]_[15728640,17039360]_[17039360,18350080]_[18350080,19660800]_<<+1310720>>_[26214400]
BATCHING: 1 prefills in batch at data_id=0, lora=default, batch_info=(256,REQ79) 
GENERATION RELOADED: unfinished_decode_ct=15, new_prefill=[(0|44|default|-351),], req_ids=[REQ79,]
TOKEN_UPDATE: first frame token generated for req=REQ79, new_pos=899, new_len=45, token=109944, bid=15, appending to context
GENERATION DECODING: len=16, examples=[(0|64),(1|126),(2|188),(3|250),(4|312),(5|372),(6|432),(7|492),(8|552),(9|612),(10|672),(11|732),(12|790),(13|847),(14|899),(15|944),], req_ids=[REQ64,REQ65,REQ66,REQ69,REQ71,REQ67,REQ70,REQ73,REQ75,REQ77,REQ68,REQ74,REQ72,REQ76,REQ78,REQ79,]
07/21/2024 07:35:57 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 16
TOKEN_UPDATE: EOS for req=REQ64, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ64, remaining block_ct=15
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=65, request_id=REQ64 first/total=(0.200929/6.579429) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ64, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ64 remaining res map/queue size=15/15
TOKEN_UPDATE: EOS for req=REQ65, mini_bid=0, start=0, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ65, remaining block_ct=14
TOKEN_UPDATE: EOS for req=REQ71, mini_bid=3, start=480, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ71, remaining block_ct=13
TOKEN_UPDATE: EOS for req=REQ67, mini_bid=4, start=640, inp/gen=44/114
KV_CACHING[gpu0]: free cache block=REQ67, remaining block_ct=12
TOKEN_UPDATE: EOS for req=REQ66, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ66, remaining block_ct=11
TOKEN_UPDATE: EOS for req=REQ69, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ69, remaining block_ct=10
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=66, request_id=REQ65 first/total=(0.50303/6.579691) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=67, request_id=REQ67 first/total=(0.905436/6.578912) secs, inp/rep=44/114 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ65, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ65 remaining res map/queue size=14/14
POOL: returning last frame 3680 logits
POOL: eos hit for request_id=REQ67, resp_token_len=115, deleting from pool.
POOL: queue after cleaning REQ67 remaining res map/queue size=13/13
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ66, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ607/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=68, request_id=REQ66 first/total=(0.501273/6.577225) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=70, request_id=REQ69 first/total=(0.502508/6.576437) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=72, request_id=REQ71 first/total=(0.403087/6.57496) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
6 remaining res map/queue size=12/12
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ69, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ69 remaining res map/queue size=11/11
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ71, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ71 remaining res map/queue size=10/10
TOKEN_UPDATE: EOS for req=REQ70, mini_bid=0, start=0, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ70, remaining block_ct=9
TOKEN_UPDATE: EOS for req=REQ73, mini_bid=1, start=160, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ73, remaining block_ct=8
TOKEN_UPDATE: EOS for req=REQ75, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ75, remaining block_ct=7
TOKEN_UPDATE: EOS for req=REQ77, mini_bid=1, start=161, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ77, remaining block_ct=6
TOKEN_UPDATE: EOS for req=REQ68, mini_bid=2, start=322, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ68, remaining block_ct=5
TOKEN_UPDATE: EOS for req=REQ74, mini_bid=3, start=483, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ74, remaining block_ct=4
TOKEN_UPDATE: EOS for req=REQ72, mini_bid=0, start=0, inp/gen=44/116
KV_CACHING[gpu0]: free cache block=REQ72, remaining block_ct=3
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ69
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ71
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=14
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ64
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=13
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=74, request_id=REQ73 first/total=(0.805099/6.579037) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=69, request_id=REQ68 first/total=(0.904929/6.679886) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ73, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ73 remaining res map/queue size=9/9
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ68, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ68 remaining res map/queue size=8/8
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ70, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ70 re07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=71, request_id=REQ70 first/total=(0.905885/6.676541) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
maining res map/queue size=7/7
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ74, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ74 remaining res map/queue size=6/6
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=75, request_id=REQ74 first/total=(0.70451/6.475201) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
TOKEN_UPDATE: EOS for req=REQ76, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ76, remaining block_ct=2
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=73, request_id=REQ72 first/total=(1.109894/6.678505) secs, inp/rep=44/116 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常对话，提供情感支持，进行闲聊等。\n5. 娱乐功能：讲笑话、唱歌、讲故事等。\n\n如果你有任何具体问题或需要帮助，都可以随时告诉我。
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=76, request_id=REQ75 first/total=(0.703906/6.474415) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3744 logits
POOL: eos hit for request_id=REQ72, resp_token_len=117, deleting from pool.
POOL: queue after cleaning REQ72 remaining res map/queue size=5/5
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ75, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ75 remaining res map/queue size=4/4
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ76, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ76 re07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=77, request_id=REQ76 first/total=(1.007296/6.474161) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=78, request_id=REQ77 first/total=(0.704383/6.474252) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
maining res map/queue size=3/3
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ77, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ77 remaining res map/queue size=2/2
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ65
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ67
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ66
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ68
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=9
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=9
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=9
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=9
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ74
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=8
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ75
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=7
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ76
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ70
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=5
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=5
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ72
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=4
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ77
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ73
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=2
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=2
TOKEN_UPDATE: EOS for req=REQ78, mini_bid=0, start=0, inp/gen=44/123
KV_CACHING[gpu0]: free cache block=REQ78, remaining block_ct=1
TOKEN_UPDATE: EOS for req=REQ79, mini_bid=0, start=0, inp/gen=44/117
KV_CACHING[gpu0]: free cache block=REQ79, remaining block_ct=0
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=79, request_id=REQ78 first/total=(0.301082/5.770788) secs, inp/rep=44/123 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项。\n4. 聊天互动：进行日常对话，提供情感支持或娱乐。\n5. 语言翻译：翻译文本或口语，支持多种语言。\n6. 娱乐功能：讲笑话、讲故事、播放音乐等。\n\n如果你有任何具体问题或需要帮助，请随时告诉我。
07/21/2024 07:36:02 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=80, request_id=REQ79 first/total=(0.200657/5.262838) secs, inp/rep=44/117 tokens; text=我可以帮助你进行多种任务，包括但不限于：\n\n1. 提供信息查询：如天气预报、新闻更新、历史事件等。\n2. 学习辅导：解答数学问题、解释科学原理、帮助学习外语等。\n3. 日常助手：提醒日程、设置提醒、管理待办事项等。\n4. 聊天互动：进行日常闲聊、分享趣事、提供情绪支持等。\n5. 娱乐功能：讲笑话、播放音乐、推荐电影等。\n\n如果你有任何问题或需要帮助，请随时告诉我。
POOL: returning last frame 3968 logits
POOL: eos hit for request_id=REQ78, resp_token_len=124, deleting from pool.
POOL: queue after cleaning REQ78 remaining res map/queue size=1/1
POOL: returning last frame 3776 logits
POOL: eos hit for request_id=REQ79, resp_token_len=118, deleting from pool.
POOL: queue after cleaning REQ79 remaining res map/queue size=0/0
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ78
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=1
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: reached eos for REQ79
07/21/2024 07:36:02 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=0
07/21/2024 07:36:07 - INFO - __main__ - after daemon cleaner queue size: 0, dict size: 0
07/21/2024 07:37:03 - INFO - serving.app - RAW REQUEST: {'request_id': 'req000001', 'query': '你需要进行以下判定，选择正确的一项陈述。\\nA: 地球是方的。\\nB: 4是奇数。\\nC: 奥巴马担任过美国总统。\\n 你需要输出上面选项中的一个，你的选择是：', 'history': [], 'role': 'user', 'gen_kwargs': {'temperature': 0.01, 'return_raw': True, 'return_logits': True, 'prefix_text': '选', 'max_new_tokens': 2}}
07/21/2024 07:37:03 - INFO - serving.pool_client - CLIENT: added request req000001, queue=1, dict=1
07/21/2024 07:37:03 - INFO - serving.ddp_worker - DDP0: submitting stream=False, record_id=81, req_id=req000001, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'return_raw': True, 'prefix_text': '选', 'max_new_tokens': 2}, role=user, hist_len=0, query=你需要进行以下判定，选择正确的一项陈述。\nA: 地球是方的。\nB: 4是奇数。\nC: 奥巴马担任过美国总统。\n 你需要输出上面选项中的一个，你的选择是：
POOL: Added to queue: request_id=req000001, queue_size=1
KV_CACHING[gpu0]: successful allocate maxlen=76, req_id=req000001. Empty memory, numel=<<+389120>>
BATCHING: 1 prefills in batch at data_id=0, lora=skip, batch_info=(76,req000001) 
CUDA MEM: data_id 0 clearing big buffer for lora switch: default->skip
GENERATION RELOADED: unfinished_decode_ct=0, new_prefill=[(0|74|skip|-706),], req_ids=[req000001,]
TOKEN_UPDATE: first frame token generated for req=req000001, new_pos=0, new_len=75, token=34, bid=0, appending to context
GENERATION DECODING: len=1, examples=[(0|75),], req_ids=[req000001,]
07/21/2024 07:37:04 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=81, request_id=req000001 first/total=(0.401848/0.401814) secs, inp/rep=74/2 tokens; text=C：
TOKEN_UPDATE WARNING: max_len causing early stop for req=req000001
KV_CACHING[gpu0]: free cache block=req000001, remaining block_ct=0
POOL: returning last frame 96 logits
POOL: eos hit for request_id=req000001, resp_token_len=3, deleting from pool.
POOL: queue after cleaning req000001 remaining res map/queue size=0/0
07/21/2024 07:37:04 - INFO - serving.pool_client - CLIENT: reached eos for req000001
07/21/2024 07:37:04 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=0
INFO:     127.0.0.1:52474 - "POST /chat HTTP/1.1" 200 OK
07/21/2024 07:37:18 - INFO - serving.app - running until complete request json:{'request_id': 'req000001', 'query': '你需要进行以下判定，选择正确的一项陈述。\\nA: 地球是方的。\\nB: 4是奇数。\\nC: 奥巴马担任过美国总统。\\n 你需要输出上面选项中的一个，你的选择是：', 'history': [], 'role': 'user', 'gen_kwargs': {'temperature': 0.01, 'return_raw': True, 'return_logits': True, 'prefix_text': '选', 'max_new_tokens': 2}}
INFO:     127.0.0.1:36946 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:37:18 - INFO - serving.pool_client - CLIENT: added request req000001, queue=1, dict=1
07/21/2024 07:37:18 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=82, req_id=req000001, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'return_raw': True, 'prefix_text': '选', 'max_new_tokens': 2}, role=user, hist_len=0, query=你需要进行以下判定，选择正确的一项陈述。\nA: 地球是方的。\nB: 4是奇数。\nC: 奥巴马担任过美国总统。\n 你需要输出上面选项中的一个，你的选择是：
POOL: Added to queue: request_id=req000001, queue_size=1
KV_CACHING[gpu0]: successful allocate maxlen=76, req_id=req000001. Empty memory, numel=<<+389120>>
BATCHING: 1 prefills in batch at data_id=0, lora=skip, batch_info=(76,req000001) 
GENERATION RELOADED: unfinished_decode_ct=0, new_prefill=[(0|74|skip|-742),], req_ids=[req000001,]
TOKEN_UPDATE: first frame token generated for req=req000001, new_pos=0, new_len=75, token=34, bid=0, appending to context
GENERATION DECODING: len=1, examples=[(0|75),], req_ids=[req000001,]
07/21/2024 07:37:19 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=82, request_id=req000001 first/total=(0.40192/0.401876) secs, inp/rep=74/2 tokens; text=C：
TOKEN_UPDATE WARNING: max_len causing early stop for req=req000001
KV_CACHING[gpu0]: free cache block=req000001, remaining block_ct=0
POOL: returning last frame 96 logits
POOL: eos hit for request_id=req000001, resp_token_len=3, deleting from pool.
POOL: queue after cleaning req000001 remaining res map/queue size=0/0
07/21/2024 07:37:19 - INFO - serving.pool_client - CLIENT: reached eos for req000001
07/21/2024 07:37:19 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=0
07/21/2024 07:37:28 - INFO - serving.app - running until complete request json:{'request_id': 'req000003', 'query': '你需要进行以下判定，选择正确的一项陈述。\\nA: 地球是方的。\\nB: 4是奇数。\\nC: 奥巴马担任过美国总统。\\n 你需要输出上面选项中的一个，你的选择是：', 'history': [], 'role': 'user', 'gen_kwargs': {'temperature': 0.01, 'return_raw': True, 'return_logits': True, 'prefix_text': '选', 'max_new_tokens': 2}}
INFO:     127.0.0.1:59890 - "POST /stream_chat_post HTTP/1.1" 200 OK
07/21/2024 07:37:28 - INFO - serving.pool_client - CLIENT: added request req000003, queue=1, dict=1
07/21/2024 07:37:28 - INFO - serving.ddp_worker - DDP0: submitting stream=True, record_id=83, req_id=req000003, gen_kwargs={'top_p': 0.9, 'temperature': 0.01, 'return_logits': True, 'return_raw': True, 'prefix_text': '选', 'max_new_tokens': 2}, role=user, hist_len=0, query=你需要进行以下判定，选择正确的一项陈述。\nA: 地球是方的。\nB: 4是奇数。\nC: 奥巴马担任过美国总统。\n 你需要输出上面选项中的一个，你的选择是：
POOL: Added to queue: request_id=req000003, queue_size=1
KV_CACHING[gpu0]: successful allocate maxlen=76, req_id=req000003. Empty memory, numel=<<+389120>>
BATCHING: 1 prefills in batch at data_id=0, lora=skip, batch_info=(76,req000003) 
GENERATION RELOADED: unfinished_decode_ct=0, new_prefill=[(0|74|skip|-238),], req_ids=[req000003,]
TOKEN_UPDATE: first frame token generated for req=req000003, new_pos=0, new_len=75, token=34, bid=0, appending to context
GENERATION DECODING: len=1, examples=[(0|75),], req_ids=[req000003,]
TOKEN_UPDATE WARNING: max_len causing early stop for req=req000003
KV_CACHING[gpu0]: free cache block=req000003, remaining block_ct=0
07/21/2024 07:37:28 - INFO - serving.ddp_worker - DDP0: REPLY for record_id=83, request_id=req000003 first/total=(0.402345/0.503463) secs, inp/rep=74/2 tokens; text=C：
POOL: returning last frame 96 logits
POOL: eos hit for request_id=req000003, resp_token_len=3, deleting from pool.
POOL: queue after cleaning req000003 remaining res map/queue size=0/0
07/21/2024 07:37:29 - INFO - serving.pool_client - CLIENT: reached eos for req000003
07/21/2024 07:37:29 - INFO - serving.pool_client - CLIENT: cleaned queue=0, dict=0
